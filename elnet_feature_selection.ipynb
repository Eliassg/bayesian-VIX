{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf42ce6-f820-4c38-9334-af5e924f24e0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658d0ba-7d38-4e1a-8fb3-c23513327f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from windowing_and_cv.tscv_sliding import TimeSeriesSplitSliding\n",
    "from window_generator import WindowGenerator\n",
    "from tensorflow.keras.losses import Huber\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8a02e-b788-431c-a5cf-13d7c6a737fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778d955-3dde-4f4c-be94-0eccad31679a",
   "metadata": {},
   "source": [
    "## Import and split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e75b29a-6308-494c-bfc8-a4fe44263138",
   "metadata": {},
   "source": [
    "Import the dataset and create train/val/test split using a *60/10/30* % split. Only the training data will be used for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100ba1b-4379-4c5e-92ce-6056777c2f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = \"stationary_dataset.csv\"\n",
    "df = pd.read_csv(directory, index_col=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d39ef5-4af2-4ebe-ae88-55e2d6d9c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create split\n",
    "n = len(df)\n",
    "train_ind = int(n*0.6)\n",
    "val_ind = int(n*0.7)\n",
    "\n",
    "train_df = df[:train_ind]\n",
    "val_df = df[train_ind:val_ind]\n",
    "test_df = df[val_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bce3e6-0014-49cf-b7d3-9515c1a0b74a",
   "metadata": {},
   "source": [
    "## Create folds for parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f4477-dcbb-4154-b666-873de919e922",
   "metadata": {},
   "source": [
    "Create the window using the `WindowGenerator` class of the `window_generator.py` module with an input width of 5 days. Values are scaled using the `MinMaxScaler` of `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ccc75-8308-4998-9fed-1d4af999d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = WindowGenerator(\n",
    "        input_width=5, label_width=1, shift=1, label_columns=['VIX'], \n",
    "        train_df=train_df, val_df=val_df, test_df=test_df, scale=True, scaler=MinMaxScaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b68635-3efe-4814-ac47-54c380ec6d76",
   "metadata": {},
   "source": [
    "Create four set of windows for cross-validation purposes on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc3c28-b87a-4368-a842-e103716ff3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = window.folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2baa8f2-8c9c-4fa0-be01-1fb0f564b22e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Perform cross-validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beeaf1b-7d96-49b3-b281-4d505a5c5e94",
   "metadata": {},
   "source": [
    "To find the best set of parameters on the training set, a `grid search` cross-validation procedure is implemented. First, specify the parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f3a1d-f56f-4491-aea5-3a3a88e3ce1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    elnet_alpha=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0],\n",
    "    elnet_l1_ratio=np.arange(0, 1, 0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29b0f0-7160-461d-8e0a-c32e427da603",
   "metadata": {},
   "source": [
    "Create and save the metrics to be utilized for evaluation as a Python *dictionary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcb23d-9b51-4c19-afb8-ac08cf750dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "huber = Huber()\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return mean_squared_error(y_actual, y_predicted, squared=False)\n",
    "metrics = {\n",
    "    \"mse\":mean_squared_error, \"mae\": mean_absolute_error, \n",
    "    \"mape\": mean_absolute_percentage_error, \"rmse\": rmse, \"huber\": huber, \"r2\":r2_score\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3d0f6-7ced-4083-85de-80ade0ad1f49",
   "metadata": {},
   "source": [
    "Next, perform the grid search on the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6bc404-10c4-4ac8-b44b-6692c9d867b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dictionary for saving hyperparameter evaluation\n",
    "param_results  = dict()\n",
    "\n",
    "# Iterate over parameters\n",
    "for alpha in param_grid[\"elnet_alpha\"]:\n",
    "    for l1_ratio in param_grid[\"elnet_l1_ratio\"]:\n",
    "        print(f\"Params: {alpha}, {l1_ratio}\")\n",
    "        results = {key:[] for key in metrics.keys()}\n",
    "        # Iterate over windows in training data\n",
    "        for fold in folds:\n",
    "            # Get data\n",
    "            train, val = fold\n",
    "            train_X = np.concatenate([x for x, y in train], axis=0)\n",
    "            train_X = train_X.reshape(len(train_X), -1)\n",
    "            train_y = np.concatenate([y for x, y in train], axis=0)\n",
    "            train_y = train_y.reshape(-1)\n",
    "            \n",
    "            val_X = np.concatenate([x for x, y in val], axis=0)\n",
    "            val_X = val_X.reshape(len(val_X), -1)\n",
    "            val_y = np.concatenate([y for x, y in val], axis=0)\n",
    "            val_y = val_y.reshape(-1)\n",
    "            # Create model\n",
    "            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=10000)\n",
    "            # Fit\n",
    "            model.fit(train_X, train_y)\n",
    "\n",
    "            # Predict\n",
    "            prediction = model.predict(val_X)\n",
    "            # Save evaluation for given fold\n",
    "            for key, metric in metrics.items():\n",
    "                score = metric(val_y, prediction.flatten())\n",
    "                results[key].append(score)\n",
    "                \n",
    "        # Compute mean for each metric over all folds\n",
    "        mean_results = {key:[] for key in metrics.keys()}\n",
    "        for key, metric in results.items():\n",
    "            mean_score = np.mean(metric)\n",
    "            mean_results[key] = mean_score\n",
    "        name = f\"alpha: {alpha}, l1_ratio: {l1_ratio}\"\n",
    "        param_results[name] = mean_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b88f2-939b-4fc0-846b-0adfad97c9e7",
   "metadata": {},
   "source": [
    "Save evaluation metrics as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865dba9-23e3-4a22-9bfd-59be77876aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = pd.DataFrame(param_results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecaf78d-707e-47bc-a25a-13a5ccadb05d",
   "metadata": {},
   "source": [
    "Display the results to find best overall set of parameters with respect to all set of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1082d10-3052-450d-8cfb-9c803e11aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in resdf.columns:\n",
    "    print(col)\n",
    "    display(resdf.sort_values(col).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ceb50-ff2d-4372-9ec2-81859f0725b2",
   "metadata": {},
   "source": [
    "# Perform the feature selection on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedef41-2f6e-4987-a8b8-768d0da6591c",
   "metadata": {},
   "source": [
    "Create 2D numpy arrays of features of the training data to use for feature selection. To do so, get the training Tensorflow `Dataset` from the window generator object, and convert into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7876b-6371-4202-835b-9b992b19bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = window.train\n",
    "\n",
    "trx = np.concatenate([x for x,y in tr], axis=0)\n",
    "trx = trx.reshape(len(trx), -1)\n",
    "ytr = np.concatenate([y for x,y in tr], axis=0)\n",
    "ytr = ytr.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6719452-c0e1-404d-8642-637675e8c44d",
   "metadata": {},
   "source": [
    "Create and fit the elastic net model using the best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b80391-fd0b-4a28-b279-7f53d3109b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(alpha=0.0001, l1_ratio=0.9, max_iter=10000)\n",
    "model.fit(trx, ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e9e99-8040-4616-9e39-7423ee24fd54",
   "metadata": {},
   "source": [
    "Get all coefficients and corresponding lags as a Pandas `Series` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63f3f4-3395-4123-8de1-4ae3d87eb763",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "flat_cols = []\n",
    "\n",
    "for i in range(window.input_width, 0, -1):\n",
    "    lag = f'_Lag_{i}'\n",
    "    for col in cols:\n",
    "        flat_cols.append(f'{col}{lag}')\n",
    "\n",
    "coeff_value = pd.Series({name: model.coef_[i] for i, name in enumerate(flat_cols)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ea9e1-89b4-4a4c-9696-1af2c7f55817",
   "metadata": {},
   "source": [
    "Display all coefficients different from zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03490654-2779-43c8-b09e-9fb07cf894a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_value[coeff_value != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384fa9a-23e1-4623-8be3-35c2dcbfc28d",
   "metadata": {},
   "source": [
    "Print all features with non-zero coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc989bce-8813-4ffb-ab58-157ffab30c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i[:-6] for i in coeff_value[coeff_value != 0].index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-venv",
   "language": "python",
   "name": "master-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
